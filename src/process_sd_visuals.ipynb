{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(csv_path):\n",
    "    '''\n",
    "    cleans up san diego traffic data for api processing\n",
    "\n",
    "    Params\n",
    "    csv_path: str of path to csv file\n",
    "    '''\n",
    "    assert isinstance(csv_path, str)\n",
    "    assert csv_path[-4:] =='.csv'\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['count'] > 5]\n",
    "    df = df[df['lat_x'].notna()]\n",
    "    df = df[df['lon_x'].notna()]\n",
    "    df = df[df['lat_y'].notna()]\n",
    "    df = df[df['lon_y'].notna()]\n",
    "    df.reset_index(drop=True)\n",
    "    df.to_csv('../processed_datasets/sd_cleaned.csv')\n",
    "\n",
    "cleanData('../processed_datasets/sd_data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Complete\n",
      "0.9900990099009901 % Complete\n",
      "1.9801980198019802 % Complete\n",
      "2.9702970297029703 % Complete\n",
      "3.9603960396039604 % Complete\n",
      "4.9504950495049505 % Complete\n",
      "5.9405940594059405 % Complete\n",
      "6.930693069306931 % Complete\n",
      "7.920792079207921 % Complete\n",
      "8.910891089108912 % Complete\n",
      "9.900990099009901 % Complete\n",
      "10.891089108910892 % Complete\n",
      "11.881188118811881 % Complete\n",
      "12.871287128712872 % Complete\n",
      "13.861386138613861 % Complete\n",
      "14.851485148514852 % Complete\n",
      "15.841584158415841 % Complete\n",
      "16.831683168316832 % Complete\n",
      "17.821782178217823 % Complete\n",
      "18.81188118811881 % Complete\n",
      "19.801980198019802 % Complete\n",
      "20.792079207920793 % Complete\n",
      "21.782178217821784 % Complete\n",
      "22.77227722772277 % Complete\n",
      "23.762376237623762 % Complete\n",
      "24.752475247524753 % Complete\n",
      "25.742574257425744 % Complete\n",
      "26.73267326732673 % Complete\n",
      "27.722772277227723 % Complete\n",
      "28.712871287128714 % Complete\n",
      "29.702970297029704 % Complete\n",
      "30.693069306930692 % Complete\n",
      "31.683168316831683 % Complete\n",
      "32.67326732673267 % Complete\n",
      "33.663366336633665 % Complete\n",
      "34.65346534653465 % Complete\n",
      "35.64356435643565 % Complete\n",
      "36.633663366336634 % Complete\n",
      "37.62376237623762 % Complete\n",
      "38.613861386138616 % Complete\n",
      "39.603960396039604 % Complete\n",
      "40.59405940594059 % Complete\n",
      "41.584158415841586 % Complete\n",
      "42.57425742574257 % Complete\n",
      "43.56435643564357 % Complete\n",
      "44.554455445544555 % Complete\n",
      "45.54455445544554 % Complete\n",
      "46.53465346534654 % Complete\n",
      "47.524752475247524 % Complete\n",
      "48.51485148514851 % Complete\n",
      "49.504950495049506 % Complete\n",
      "50.495049504950494 % Complete\n",
      "51.48514851485149 % Complete\n",
      "52.475247524752476 % Complete\n",
      "53.46534653465346 % Complete\n",
      "54.45544554455446 % Complete\n",
      "55.445544554455445 % Complete\n",
      "56.43564356435643 % Complete\n",
      "57.42574257425743 % Complete\n",
      "58.415841584158414 % Complete\n",
      "59.40594059405941 % Complete\n",
      "60.396039603960396 % Complete\n",
      "61.386138613861384 % Complete\n",
      "62.37623762376238 % Complete\n",
      "63.366336633663366 % Complete\n",
      "64.35643564356435 % Complete\n",
      "65.34653465346534 % Complete\n",
      "66.33663366336634 % Complete\n",
      "67.32673267326733 % Complete\n",
      "68.31683168316832 % Complete\n",
      "69.3069306930693 % Complete\n",
      "70.29702970297029 % Complete\n",
      "71.2871287128713 % Complete\n",
      "72.27722772277228 % Complete\n",
      "73.26732673267327 % Complete\n",
      "74.25742574257426 % Complete\n",
      "75.24752475247524 % Complete\n",
      "76.23762376237623 % Complete\n",
      "77.22772277227723 % Complete\n",
      "78.21782178217822 % Complete\n",
      "79.20792079207921 % Complete\n",
      "80.1980198019802 % Complete\n",
      "81.18811881188118 % Complete\n",
      "82.17821782178218 % Complete\n",
      "83.16831683168317 % Complete\n",
      "84.15841584158416 % Complete\n",
      "85.14851485148515 % Complete\n",
      "86.13861386138613 % Complete\n",
      "87.12871287128714 % Complete\n",
      "88.11881188118812 % Complete\n",
      "89.10891089108911 % Complete\n",
      "90.0990099009901 % Complete\n",
      "91.08910891089108 % Complete\n",
      "92.07920792079207 % Complete\n",
      "93.06930693069307 % Complete\n",
      "94.05940594059406 % Complete\n",
      "95.04950495049505 % Complete\n",
      "96.03960396039604 % Complete\n",
      "97.02970297029702 % Complete\n",
      "98.01980198019803 % Complete\n",
      "99.00990099009901 % Complete\n"
     ]
    }
   ],
   "source": [
    "def points(start_lat,start_lng,end_lat,end_lng):\n",
    "    '''\n",
    "    makes an api call to route and directions to get a list of coordinates of the shortest path between two geographical coordinates\n",
    "\n",
    "    Params\n",
    "    start_lat: the origin lattitude\n",
    "    start_lng: the origin longitude\n",
    "    end_lat: the destination lattitude\n",
    "    end_lng: the destination longitude\n",
    "    '''\n",
    "    assert isinstance(start_lat, str)\n",
    "    assert isinstance(start_lng, str)\n",
    "    assert isinstance(end_lat, str)\n",
    "    assert isinstance(end_lng, str)\n",
    "\n",
    "    import requests\n",
    "\n",
    "    url = \"https://route-and-directions.p.rapidapi.com/v1/routing\"\n",
    "    querystring = {\"waypoints\":f\"{start_lat},{start_lng}|{end_lat},{end_lng}\",\"mode\":\"drive\"}\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"INSERT-YOUR-KEY-HERE\",\n",
    "        \"X-RapidAPI-Host\": \"route-and-directions.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    return response\n",
    "\n",
    "\n",
    "def getCoordinates(csv_file):\n",
    "    '''\n",
    "    reads a csv file of starting and ending locations, creates a csv file of points of all the paths traveled\n",
    "\n",
    "    Params\n",
    "    csv_file- str to csv file location\n",
    "    '''\n",
    "    assert isinstance(csv_file, str)\n",
    "\n",
    "    import pandas as pd\n",
    "    df_tester = pd.read_csv(csv_file)\n",
    "\n",
    "    points_list = []\n",
    "    for i in range(len(df_tester)):\n",
    "        print(i*100/(len(df_tester)), '% Complete')\n",
    "\n",
    "        count = str(df_tester['count'].loc[i])\n",
    "        start_lat = str(df_tester['lat_x'].loc[i])\n",
    "        start_lng = str(df_tester['lon_x'].loc[i])\n",
    "        end_lat = str(df_tester['lat_y'].loc[i])\n",
    "        end_lng = str(df_tester['lon_y'].loc[i])\n",
    "\n",
    "        #makes an api call to get a list of coordinates as a JSON request response\n",
    "        coordinates = points(start_lat,start_lng,end_lat,end_lng)\n",
    "\n",
    "        if coordinates.ok:\n",
    "            points_json = coordinates.json()\n",
    "            points_list.append(points_json)\n",
    "        else:\n",
    "            points_list.append(\"nope\")\n",
    "\n",
    "    #adds the coordinates to the df\n",
    "    df_tester['coordinates'] = points_list\n",
    "\n",
    "    #cleans the data of error responses from the api\n",
    "    df_tester = df_tester[df_tester['coordinates'] != \"nope\"]\n",
    "    df_tester = df_tester[df_tester['coordinates'] != \"{'statusCode': 400, 'error': 'Bad Request', 'message': 'No path could be found for input'}\"]\n",
    "    df_tester.to_csv('../processed_datasets/sd_final.csv')\n",
    "\n",
    "\n",
    "getCoordinates('../processed_datasets/sd_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_coordinates():\n",
    "    '''\n",
    "    Creating a dataset with all the location names and their respective coordinates.\n",
    "    Requires the cleaned dataset sd_cleaned.csv to be present in the processed_datasets folder.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('../processed_datasets/sd_cleaned.csv')\n",
    "\n",
    "    df_locs = df[['start_loc', 'end_loc',  'lat_x', 'lon_x', 'lat_y', 'lon_y']]\n",
    "    df_locs.rename(columns = {'lat_x':'start_lat', 'lon_x':'start_lng', 'lat_y':'end_lat', 'lon_y':'end_lng'}, inplace=True)\n",
    "\n",
    "    df_locs_start = df_locs[['start_loc','start_lat','start_lng']]\n",
    "    df_locs_end = df_locs[['end_loc','end_lat','end_lng']]\n",
    "\n",
    "    # Averaging coordinate values for start locations and end locations\n",
    "    df_locs_start = df_locs_start.groupby(['start_loc'])[['start_lat','start_lng']].agg('mean')\n",
    "    df_locs_end = df_locs_end.groupby(['end_loc'])[['end_lat','end_lng']].agg('mean')\n",
    "\n",
    "    df_locs_start.rename(columns = {'start_lat':'lat','start_lng':'lng'},inplace=True)\n",
    "    df_locs_start.reset_index()\n",
    "    df_locs_end.rename(columns = {'end_lat':'lat','end_lng':'lng'},inplace=True)\n",
    "    df_locs_end.reset_index()\n",
    "\n",
    "    df_locs_metadata = pd.concat([df_locs_start,df_locs_end])\n",
    "    df_locs_metadata = df_locs_metadata.reset_index()\n",
    "\n",
    "    df_locs_metadata = df_locs_metadata.drop_duplicates(subset='index')\n",
    "    df_locs_metadata.to_csv('../processed_datasets/sd_location_coordinates.csv')\n",
    "\n",
    "\n",
    "def extract_total_counts_per_loc():\n",
    "    '''\n",
    "    Finding total counts (sum of counts of rides where it was start or end point) for each location. This is used for hotspot visualization.\n",
    "    Requires the cleaned dataset sd_cleaned.csv to be present in the processed_datasets folder.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv('../processed_datasets/sd_final.csv')\n",
    "    data = data.drop(columns='Unnamed: 0')\n",
    "\n",
    "    # Aggregate counts by start and end locations\n",
    "    start_locs = data.groupby('start_loc')[[\"count\"]].sum().reset_index()\n",
    "    end_locs = data.groupby('end_loc')[[\"count\"]].sum().reset_index()\n",
    "\n",
    "    locs = start_locs.merge(end_locs, left_on='start_loc', right_on='end_loc', how='outer', indicator=True)\n",
    "\n",
    "    # Mark locations on the basis of whether they are ride start points only, ride end points only, or both\n",
    "    locs.loc[locs[\"_merge\"] == \"left_only\", \"loc\"] = locs[\"start_loc\"]\n",
    "    locs.loc[locs[\"_merge\"] == \"left_only\", \"total_count\"] = locs[\"count_x\"]\n",
    "\n",
    "    locs.loc[locs[\"_merge\"] == \"right_only\", \"loc\"] = locs[\"end_loc\"]\n",
    "    locs.loc[locs[\"_merge\"] == \"right_only\", \"total_count\"] = locs[\"count_y\"]\n",
    "\n",
    "    locs.loc[locs[\"_merge\"] == \"both\", \"loc\"] = locs[\"start_loc\"]\n",
    "    locs.loc[locs[\"_merge\"] == \"both\", \"total_count\"] = locs[\"count_x\"] + locs[\"count_y\"]\n",
    "\n",
    "    locs = locs.drop(columns=['start_loc', 'end_loc', 'count_x', 'count_y'])\n",
    "    locs = locs.rename(columns={'_merge':'type'})\n",
    "    locs[\"type\"].cat.rename_categories({'left_only':'start_only', 'right_only':'end_only'}, inplace=True)\n",
    "\n",
    "    lat_lngs = pd.read_csv('../processed_datasets/sd_location_coordinates.csv')\n",
    "    lat_lngs = lat_lngs.drop(columns='Unnamed: 0')\n",
    "    locs = locs.merge(lat_lngs, left_on='loc', right_on='index', how='left')\n",
    "    locs = locs.drop(columns=['index'])\n",
    "    locs = locs.sort_values(by='total_count', ascending=False)\n",
    "    locs = locs[['loc', 'total_count', 'lat', 'lng', 'type']]\n",
    "    locs = locs.dropna()\n",
    "    locs = locs.reset_index(drop=True)\n",
    "\n",
    "    locs.to_csv('../processed_datasets/sd_hotspots.csv')\n",
    "\n",
    "extract_location_coordinates()\n",
    "extract_total_counts_per_loc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
